malloc: Implementing a dynamic memory allocation mechanism


malloc:
	the malloc function allocates size bytes and returns a pointer to the
	allocated memory. the memory is not initialized.
	if size if 0, then malloc() returns a unique pointer value that can
	later be successfully passed to free().

free:
	the free() function frees the memory space pointed to by ptr, which must
	have been returned by the previous call to malloc() or related functions.
	otherwise, or if the ptr has already been freed, undefined behavior occurs.
	if ptr is NULL, no operation is performed.

RETURN VALUE:
	the malloc, function return a pointer to the allocated memory,
	which is suitably aligned for any type that fits into the requested size or
	less. on error, these functions return NULL and set errno.
	attemting to allocate more than PTRDIFF_MAX bytes is considered an error,
	as an object that large could sause later pointer substraction to overflow.

ERRORS
	malloc can fail with the following error.
	ENONEM Out of memory, possibly the application hit the RLIMIT_AS or RLIMIT_DATA
	limit described in getrlimit, another reason could be that the number of
	mapping created by the caller process exceeded the limit specified by 
	/proc/sys/vm/max_map_count.

ATTRIBUTES
	Thread safety: MT-Safe.


heap:
the heap segment contains dynamically allocated memory,
commonly begins at the end of the BSS segement and grows to larger addresses
from there.
it is managed by malloc, calloc, realloc, and free
which may use the brk, sbrk system calls to adjust its size .
they may also be implemented using mmap/munmap to reserve/unreserve potentially
non-contigious regions of virtual memory into the process's virtual address space.
the heap segment is shared by all threads, shared libraries, and dynam loaded
modules in a process.


brk and sbrk are basic memory management system calls used in Unix and Unix-like
operating systems to control the amount of memory allocated to the heap segment
of the process.

the brk and sbrk calls dynamically change the amount of space allocated for the
heap segment of the calling process.
the change is made by resetting the program break of the process.
which determines the maximum space that can be allocated.
the program break is the address of the first location beyond the current end of
data segment.
the amount of available space increases as the break value increases.
the available space is initialized to  a value of zero.
the break value can be automatically rounded up to a size appropriate for the
memory managment architecture.



The C language guaranted that all uninitialized global variables will be
initialized to zero.

When C programs are compiled, a seperate section called .bss is used for 
uninitialized variables.
Since the value of these variables are all zeros to start with, they do not have
to be stored in "Flash". before transfering control to C code, the memory 
locations corresponding to these variables have to be initialized to zero.

GCC places global variables marked as const in a seperate section, called .rodata
the .rodata is also used for storing string constants.

Since contents of .data section will not be modified, they can be placed in "Flash"

the linker script has to modified to accomodate this.


- Process Memory Concepts:

one of the most basic resources a process has available to it is memeory.

each process has one linear virtual address space.
with addresses running from zero to some huge maximum.
it need not be contigeous, not all of these addresses actually can be used to
store data.

the virtual memory is divided into pages (4kB). Backing each page of virtual
memory is a page of real memory (called a frame) or some secondary storage, usually
disk space.
the disk space might be swap space or just some ordinary disk file.
a page of zeroes sometimes has nothing at all backing it.

the same frame of real memory or backing store can back multiple virtual pages
belonging to multiple processes 
this is normally the case for example, with virtual memory occupied by GNU C 
library code.
the same real memory frame containing the printf function backs a virtual
memory page in each of the existing processes that has a printf call in its 
program.

in order for a program to access any part of a virtual page, the page must 
at that moment be backed by "connected to" a real frame.
but because there is usually a lot more virtual memory than real memory,
the pages must move back and forth between real memory and backing 
store regularly, coming into real memory when a process needs to access them
and then retreating to backing store when not needed anymore.
this movement is called paging.

when a program attempts to access a page which is not at that moment backed by 
real memory, this is known as 'page fault'.
when a page fault occurs, the kernel suspends the process, places the page into
a real page frame (this is called 'paging in' or 'faulting in')
then resumes the process so that from the process's point of view, the page was 
in real memory all along.
in fact, to the process, all pages always seems to be in real memory.
Except for one thing; the elapsed execution time of an instrction that would normally 
be a few nanoseconds is suddenly much, much longer (because the kernel normally has to bo
I/O to complete the page-in).

within each virtual address space, a process has to keep track of what is at 
which addresses. and that process is called memory allocation.


memory-mapped I/O is another form of dynamic virtual memory allocation.
mapping memory to a file means declaring that the contents of 
certain range of a process addresses shall be identical to the contents of a 
specified file.
the system makes the virtual memory initially contain the contents fo the file.
and if you modify the memory, the system writes the same modification to the file.



dynamic memory allocation is a technique in which programs determine as they are 
running where to store some information.

you need dynamic allocation when the amount of memory you need, or how long you
continue to need it, depends on factors that are not known before the program 
runs.

the only way to get dynamically allocated memory is via a system call.
(which is generally via a GNU C library function call).
and the only way to refer to dynamically allocated space is through a pointer.
because it is less convenient and because the actual process of dynamic allocation 
requires more computation time.
programmers generally use dynamic allocation only when neither static
nor automatic allocation will serve.

- The GNU Allocator
the malloc implementation in the GNU C library is derived from the ptmalloc
(pthreads malloc), which in turn is derived from the dlmalloc (Doug Lea malloc).

this malloc may allocate memory in two different ways depending on their size 
and certain parameters that may be controlled by users 
the most common way is allocating portions of memory (called chunks) from a large
contiguous area of memory and manage these areas to optimize their use and reduce 
wastage in the form of unusable chunks.
traditionally the system heap was set up to be the one large memory area but 
GNU C library malloc implementation maintains multiple such areas to optimize 
their use in multi-threaded applications.
Each such area is internally referred to as arena.

As opposed to other versions, the malloc in the GNU C Library does not round up
chunk size to powers of 2, neither for large nor for small sizes.
Neiboring chunks can be coalesced on a free no matter what their size is.

this makes the implementation suitable for all kinds of allocation patterns 
without generally incurring high memory waste through fragmenation.

the presence of multiple arenas allows multiple threads to allocate memory 
simultaneously in seperate arenas, thus improving performance.

the other way of memory allocation is for very large blocks, 
much larger than a page.
this requests are allocated with mmap (anonymous or via /dev/zero)
this has the great advantage that these chunks are returned to the system 
immediately when they are freed.
therefor, it cannt happen that a large chunk becomes "locked" in between smaller
ones and even after calling free wastes memory.
the size threashold for mmap to be used is dynamic and gets adjusted according
to allocation patterns of the program.


the most general dynamic allocation facility is malloc
it allows you to allocate blocks of memory of any size at any time.
make them bigger or smaller at any time, and free the blocks individually
at any time (or never).

the block that malloc gives you is guaranted to be aligned so that 
it can hold any type of data.

on GNU systems, the address is always a multiple of eight on 32-bit systems,
and multiple of 16 on 64-bit.

the memory located after the end of the block is likely to be in use for something
else; perhaps a block already allocated by another call to malloc, if you attempt
to treat the block as longer than what you asked for it to be, you are liable
to distroy the data that malloc uses to keep track of it's blocks, or you may 
destroy the contents of a another block.
if you have already allocated a block and discover you want it to be bigger,
use realloc.


Portability Note:
	- in the GNU C Library, a successful malloc(0) returns a non-null pointer to
	a newly allocated size-zero block.
	other implementations may return NULL instead, POSIX and ISO C standard allow
	both behaviors.

	- in the GNU C Library, a failed malloc call sets errno, but ISO C does 
	not require this and non-POSIX implementation need not set 
	errno when failing.

	- in the GNU C Library, malloc always fails when size exceeds PTRDIFF_MAX,
	to avoid problems with programs that substract pointers or use signed indexes

Ocationally, free can actually return memory to the operating system and make
the process smaller.
usually, all it can do is allow a later call to malloc to reuse the space.
in the meantime, the space remains in your program as part of a free-list used
internally by malloc.


the free function preserve the value of errno, so that cleanup code need not worry
about saving and restoring errno around a call to free.

Replacing malloc:
the GNU C library supports replacing the built-in malloc implementation with 
a different allocator with the same interface.
For dynamically linked programs this happens through ELF symbol interposition,
either using shared object dependencies or LD_PRELOAD.
for static linking, the malloc replacement library must be linked in before
linking against libc.a (explicitly or implicitly).
!! failure to provide complete set of replacement functions 
(that is all the functions used by the application, the GNU C Library, and other
linked-in libraries) can lead to static linking failure, and at run time, to heap 
corruption and application crashes.
replacement functions should implment the behavior documented to their counterparts
in the GNU C Library,

the minimum set of functions which has to be provided by a custom malloc is given
in the table below,
	* malloc
	* free
	* calloc
	* realloc

these malloc-related functions ar erequired for the GNU C Library to work.

the malloc implementation in the GNU C Library provides addictional functionality
not used by the library itself, but which is often used by other system libraries 
and applications.

A general-purpose replacement malloc implementation should provide definitions 
of these functions too. their names are listed in the following table.

	* aligned_alloc
	* malloc_usable_size
	* memalign
	* posix_memalign
	* pvalloc
	* valloc
in Addition, very old applications may use the obsolute cfree funtion.

Further malloc-related functions such as mallopt or mallinfo2 will not have any
effect or return incorrect statistics when a replacement malloc is in use.
However failure to replace these fucntions typically does not result in crashes 
or other incorrect application behavior, but may result in static linking failure.



the address of a block returned by malloc or realloc in GNU systems is always 
a multiple of eight (or 16 on 64-bit systems)

Malloc Tunable Parameters:

you can adjust some parameters for the dynamic memory allocation with mallopt 
function.
this function is the general SVID/XPG interface, defined in malloc.h

	int mallopt(int param, int value)

	possible choices for param:
	M_MMAP_MAX:
		the maximum number of chunks to allocate with mmap, setting to 0 disables 
		all use of mmap.
		the default value of this parameter is 65536.
		
		ENV_VAR: MALLOC_MMAP_MAX_
	
	M_MMAP_THRESHOLD:
		all chunks larger than this value are allocated outside of the normal heap,
		using the mmap system call,
		this way it is guaranted that the memory for these chunks can be returned
		to the system on free
		not that requests smaller than this threashold might still be allocated via mmap
		
		if this parameter is not set, the default value is set as 128KiB and the 
		threashold is adjusted dynamically to suit the allocation patterns of
		the program. if the parameter is set, the dynamic adjustement wis disabled
		and the value is set statically to the input value.

		MALLOC_MMAP_THRESHOLD_

	M_TOP_PAD:
		this parameter determines the amount of extra memory to obtain from the
		system when an arena needs to be extended. it also specifies the number of
		bytes to retain when shrinking an arena.
		this provide the necessary hysteresis in heap size such that excessive
		amounts of system calls can be avoided.

		the default value of this parameter is 0.
		MALLOC_TOP_PAD_
	
	M_TRIM_THRESHOLD:
		this is the minimum size (in bytes) of the top-most, releasable chunk 
		that will trigger a system call in order to return the memory to the
		system
	
	M_ARENA_TEST:
		this parameter specifies the number of arenas that can be created 
		before the test on the limit to the number of arenas is conducted.

		the default value of this parameter is 2 on 32-bit systems and 8 on 64-bit systems.
	
		MALLOC_ARENA_TEST
	
	M_ARENA_MAX:
		this parameter sets the number of arenas to use regardless of the number of cores
		in the system.

		the default value of this tunable is 0, meaning that the limit 
		on the number of arenas is determined by the number of CPU cores online.

		for 32-bit systems the limit is twice the number of core online 
		and on 64-bit system, it is 8 times the number of cores online.


Statistics from Memory Allocation with malloc

you can get information about the dynamic memory allocation by calling mallinfo2
function. This function and its associated data type are decalred in malloc.h

they are an extension of the standard SVID/XPG version.

---Memory-mapped I/O:
On modern operating systems, it is possible to mmap a file to a region of memory.
when this is done the file can be accessed just like an array in the program.

this is more effiecient than read or write, as only the regions of the file that
a program actually accesses are loaded.

Accesses to not-yet loaded parts of the mmpped region handled in the same way as
swapped pages.

Since mmaped pages can be stored back to their file when physical memory is low,
it is possible to mmap files orders of magnitude larger than both the physical 
memory and swap space.
the only limit is address space

Memory mapping only works on entire pages of memory. thus, addresses for mapping
must be page-aligned, and length value will be rounded up
to determine the default size of a page the machine uses one should use:
	size_t page_size = (size_t) sysconf (_SC_PAGESIZE);

the mmap function creates a new mapping, connected to bytes (offset) to (offset + length - 1)
in the file open on filedes.
a new reference on the file specified by filedes is created, which is not removed
by closing the file.


flags:
	MAP_ANON:
		this flags tells the system to create an anonymous mapping, not connected 
		to a file. filedes and offset are ignored, and the region is initialized
		with 0.

		Anonymous maps are used as the basic primitive to extend the heap on 
		some systems.
		they are also useful to share data between multiple tasks without creating
		a file.


		on some systems using private Anonymous mmaps is more effiecient than using
		malloc for large blocks. this is not an issue with the GNU C Library,
		as the included malloc automatically uses mmap where appropriate.

Resizing the Data Segment:
	int brk(void *addr)
	brk sets the high end of the calling process' data segment to addr,

	the address of the end of a segment is defined to be the address of the last
	byte in the segment plus 1.

	void *sbrk(ptrdiff_t delta)
	this function is same as brk except that you specify the new end of the 
	data segment as an offset delta fron the current end and on success the return value 
	is the address of the resulting end of the data segment instead of zero.


File-backed and anonymous:
File backed mappings maps an area of the process's virtual memory to files;
that is, eading those areas of memory causes the file to be read. it is the
deafult mapping type.

Anonymous mapping maps an area of the process's virtual memory not backed 
by any file. the contents are initialized to zero.
in this respect an anonymous mapping is similar to malloc, and is used in some
malloc implementations for certain allocations, particularly large ones.


A memory-mapped file is a segment of virtual memory.
that has been assigned a direct byte-for-byte correlation with some portion 
of a file or file-like resource.
this resource is typically a file that is physically present on disk, but can also
be a device, shared memory object, or other resource that an operating system 
can reference through a file descriptor.


the allocator does not examine the data stored in a block, or modify or act on 
it in any way.
the data areas within blocks that are used to hold objects are contiguous and 
nonoerlapping ranges of (real or virtual) memory.

the worst case performance of any general allocator amounts to complete failure
due to memory exhaustion or virtual memory thrashing 

What an Allocator Must do:
- keep track of which parts of memory are in use, and which parts are free.
- minimize wasted space without undue time cost, or vice versa.

the ideal allocator would spend negligible time managing memory, and waste 
negligible space.

 - it must respond immediately to request for space, and once it has decided 
 which block of memory to allocate, it cannot change that decision.
 - Allocators record the locations and sizes of free blocks of memory in some kind 
 of hidden data structure. which may be a linear list, a totally or partially 
 ordered tree, a bitmap, or some hybrid data strcuture.
 - An Allocator is therefore an online algorithm, which must respond to requests
 in strict sequence, immediately, and its decisions are irrevocable.

 - The problem the allocator must address is that the application program may
 free blocks in any order, creating 'holes' amid live objects 
 - if these holes are too numerous and small, they cannot be used to satisfy
 future requests for larger blocks
 this problem is known as fragmenation

 !!! it has been proven that for any possible allocation algorithm, there will
 always be the possiblity that some application program will allocate and deallocate
 blocks in some fashion that defeats the allocator's strategy, and force it into
 severe fragmenation.
 !!!>>>> Not only are there no provably good allocation algorithms, there are
 proofs that any allocator will be 'bad' for some possible applications.


 the design of memory allocators is currently something of a black art.

 --> there are regularities in program behavior that allocators exploit.
 - these regularities are exploited by allocators to prevent excessive fragmenation

 the main technique used by allocators to keep fragmentation under control is
 placement choice.
 two subsidiary technique techniques are used to help implement that choice:
	- splitting blocks to satisfy smaller requests.
	- coalescing of free blocks to yield larger blocks.

Placement choice is simply the choosing of where in free memory to put a requested
block.

it can place a requested block anywhere it can find a sufficiently large range
of free memory and anywhere within that range.

=============================
An Allocator algorithm therefore should be regarded as the mechanism that 
implements a placement policy which is motivated by a strategy for minimizing 
fragmentation 
============================

Strategy:
	the strategy takes into account regularities in program behavior.
	and determines a range of acceptable policies as to where to allocate
	requested blocks.
	the chosen policy is implemented by a mechanism, which is a set of 
	algorithms and the data strctures they use.

strategy: attempts to exploit regularities in request stream.
policy: is an implementable decision procedure for placing blocks in memory.
mechanism: is a set of algorithms and data structures that implement the
	policy, often over-simply called 'an algorithm'.

the corresponding (best fit) policy is more concrete-it says "always use the
smallest block that is at least large enough to satisfy the request"

the placement policy determines exactly where in memory requested blocks will 
be allocated for the best fit policies

for the best fit policies, the general rule is 'allocate objects in the smallest
free block that's at least big enough to hold them'

the chosen policy is implemented by a specific mechanism, chosen to implement 
that policy efficiently in terms of time and space overheads.

for best fit, a linear list or ordered tree structure might be used to record 
the addresses and sizes of free blocks.
and a tree seach or list search would be used to find the one dictated by the 
policy.



---- Splitting and Coalescing ----
The allocator may split large blocks into smaller blocks arbitrary, and use
any sufficiently-large subblock to satisfy future requests.

the remainders from this splitting can be recorded as smaller free blocks in 
their own right and used to satisfy future requests.

the allocator may also coalesce adjacent free blocks to yield larger free 
blocks.

after a block is freed, th allocator may check to see whether the neighboring
blocks are free as well, and merge them into a single, larger block.

this is often desirable, because one large block is more likely to be useful 
than two small ones, larger or small requests can be satisfied from large 
blocks.

the cost may not be negligible, however, especially if splitting and coalescing
work too well, in that case, freed blocks will usually be coalesced with 
neighbors to form large blocks of free memory, and later allocations will 
have to split smaller chunks off of those blocks to obtain the desired sizes.

it often turns out that most of this effort is wasted, because the sizes 
requested later are largely the same as the sizes freed earlier.
and the old small blocks could have been reused witout coalescing and 
splitting.

Because of this, many modern allocators use deffered coalscing, they avoid 
coalescing and splitting most of the time. but use it intermittely, to combat
fragmenation.

the Allocator should embody a strategy designed to exploit regularities in 
program behavior, otherwise it cannot be expected to do particularly well.


Fragmentation:
	is the inability to reuse memory that is free.

the problem is a function both of the program's request stream and the
allocator's choices of where to allocate the requested objects.

An Allocator's inability to reuse memory depends not only on the number and 
sizes of holes, but on the future use behavior of the program, and the future
responses of the allocator itself.


Header fields and Alignement:
Most allocators use a hidden 'header' field within each block to store useful
information.
the size of the block is recorded in the header.

having information about the block stored with the block makes many common 
operations fast.

in most situations, there is enough room in one machine word to store a 
size field plus two or three on-bit 'flags'.

alignement means that partial words cannot be allocated-requests for
non-integral numbers of words are rounded up to the nearest word.

to support the coalscing of free areas. each block of memory has a both 
header and footer field, both of which record the size of the block and whether
it is in use.

when a block is freed, the footer of the preceding block of memory is examined.
adjacent free areas are merged to form larger free blocks.

Header anf footer overhead are likely to be significant
with an average object size of about 10 words,
for example, a one-word header incurs a 10% overhead and a one-word footer 
incurs another 10%.


when a block is in use (holding a live object), the size field in the footer
is not actually needed-all that is needed is the flag bit saying that the storage
is an available for coalescing, the size field if only needed when the block is 
free, so that it's head can be located for coalescing.
the size field can therfore be taken out of the last word of the block of memory 
when the block is allocated. it can be used to hold part of the object.
when the object is freed, the size field can be copied from the header into the 
footer, because that space is not longer needed to hold part of the object.

the single bit needed to indicate whether a block is in use can be stolen
from the header word of the following block without unduly limiting 
the range of the size field.

link fields within blocks: for allocators using free lists or indexing trees to
keep track of free blocks the list or tree nodes are generally embodded in the 
free blocks themselves.
since only free blocks are recorded, and since their space would otherwise 
be wasted, it is usually considered reasonable to use the space within the 
"empty" blocks to hold pointers linking them together. space for indexing 
structure is therefore "free" (almost).

Many systems use doubly-linked linear lists, with a "previous" and "next" pointer 
taken out of the free area.


the hidden cost of putting link fields within blocks is that the block must 
be big enough to hold them, along with the header field and footer field
this imposes a minimum block size on the allocator implementation 
and any smaller requests must be rounded up to that size.

A common situation is having a header with a size field and boundary tags, 
plus two pointers in each block.


Lookup Table:
	Some allocators treat blocks within ranges os sizes similarly-rather 
	than indexing free blocks by their exact size, they lump together blocks
	of roughly the same size, the size range may also be important to the
	coalesing mechanism. Powers of two are coarse, however, and can have
	drawbacks.

in most systems, many more small objects are allocated than large ones,
it is therfore often worthwhile to treat small objects specially, in one 
sense or another, this can usually be done by havning the allocator 
check to see if the size is small, and if so, use an optimized technique 
for small values, for large values, it may use slower technique.


the basic idea here is to ensure that the time spent allocating a block is 
small relative to the computations on the data it holds.

The allocator allocates memory to programs on request, but the allocator 
itself must get memory from somewhere.

the most common situation in modern systems is that the heap occupies a range 
of virtual addresses and grows 'upward' through the address space.

to request more virtual memory a system call such as the UNIX brk() call 
is used to request that storage can be mapped to that region of address space.
so that it can be used to hold data.

typically the allocator keeps a 'high-water mark' that divides the memory
into the part that is backed by storage and the part that is not.

we will genrally assume that a paged virtual memrory is in use. in that case
the sytem call that obtains more memory obtains some integral number of pages.


-- Sequential Fits -----

several classic allocator algorithms are based on having a single linear list
of all free blocks of memory.

the list is often doubly-linked and/or circularly-linked.
Typically, sequential fits algorithms use knuth's boundary tag technique, and 
a doubly-linked list to make coalescing simple and fast.

Best fit:
	A best fit sequential fits allocator searches the free list to find the 
	smallest free block large enough to satisfy a request.

First Fit:
	simply searches the list from the beginning, and uses the first free block
	large enough to satisfy the request. if the block is larger than necessary,
	it is split and the remainder is put on the free list.

	A problem with sequential first fit is that the larger blocks near the 
	begining of the list tend to be split first, and the remaining fragments
	result in having a lot of small blocks near the beginning of the list.

Segregated Free Lists:
	one of the 